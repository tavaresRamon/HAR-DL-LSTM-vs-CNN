% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  a4paper,
]{article}
\usepackage{xcolor}
\usepackage[top=2cm,bottom=2cm,left=2.5cm,right=2.5cm]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Análise Comparativa de Arquiteturas de Deep Learning (Stacked LSTM vs.~1D-CNN) no Reconhecimento de Atividades Humanas},
  pdfauthor={Ramon Lima de Oliveira Tavares},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Análise Comparativa de Arquiteturas de Deep Learning (Stacked
LSTM vs.~1D-CNN) no Reconhecimento de Atividades Humanas}
\author{Ramon Lima de Oliveira Tavares}
\date{2025-08-12}
\begin{document}
\maketitle


\section{Introdução}\label{introduuxe7uxe3o}

O monitoramento automático de atividades humanas (HAR - \emph{Human
Activity Recognition}) consolidou-se como vetor de inovação na saúde
digital (Lara \& Labrador, 2013). Sensores inerciais miniaturizados
geram fluxos de dados contínuos que, processados por algoritmos
inteligentes, permitem inferir comportamentos complexos.

A problemática central reside na natureza estocástica e ruidosa das
séries temporais do movimento humano. Enquanto métodos clássicos
dependem de \emph{feature engineering} manual, o Aprendizado Profundo
(\emph{Deep Learning}) aprende representações hierárquicas diretamente
dos dados brutos (LeCun et al., 2015).

Este trabalho propõe um estudo comparativo rigoroso entre \textbf{Redes
Neurais Convolucionais (1D-CNN)}, focadas em padrões locais (Kiranyaz et
al., 2021), e \textbf{Redes Recorrentes (Stacked LSTM)}, focadas em
dependências temporais (Hochreiter \& Schmidhuber, 1997). O objetivo é
avaliar a eficácia preditiva e a eficiência paramétrica de cada
topologia no \emph{dataset} UCI HAR.

\section{Fundamentos Teóricos e
Dados}\label{fundamentos-teuxf3ricos-e-dados}

\subsection{Caracterização do Dataset UCI
HAR}\label{caracterizauxe7uxe3o-do-dataset-uci-har}

O estudo utiliza dados de 30 voluntários (19-48 anos) realizando
Atividades de Vida Diária (ADL) com um \emph{smartphone} na cintura,
amostrado a 50Hz (Anguita et al., 2013).

\begin{center}
\textbf{Figura 1: Sistema de Coordenadas do Smartphone}
\end{center}

\begin{center}
\includegraphics[width=0.25\linewidth,height=\textheight,keepaspectratio]{figuras_artigo/fig_smartphone_axis.png}
\end{center}

\begin{center} \small Fonte: Adaptado de Anguita et al. (2013). \end{center}

\subsection{Análise Visual dos Sinais
Temporais}\label{anuxe1lise-visual-dos-sinais-temporais}

A complexidade do problema é evidenciada na visualização dos dados
brutos. A Figura 2 demonstra a diferença estocástica entre atividades
\textbf{Dinâmicas} (alta variância, picos agudos) e \textbf{Estáticas}
(baixa amplitude, ruído constante).

\begin{center}
\textbf{Figura 2: Comparativo de Sinais Brutos (Janela 2.56s)}
\end{center}

\begin{center}
\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{figuras_artigo/fig_sinais_temporal_grid.png}
\end{center}

\begin{center} \small Legenda: Sinais normalizados de Aceleração e Giroscópio. Note a estacionariedade nas classes "Sentado", "Em Pé" e "Deitado". Fonte: Elaborada pelo autor. \end{center}

\subsection{Estrutura Algébrica e
Volumetria}\label{estrutura-alguxe9brica-e-volumetria}

\subsubsection{1. Definição de uma Amostra Única
(Janela)}\label{definiuxe7uxe3o-de-uma-amostra-uxfanica-janela}

Cada instância de dado (\(X^{(i)}\)) é uma matriz densa representando
2,56 segundos de movimento contínuo.

\[
X^{(i)} = 
\begin{bmatrix} 
\text{BodyAccX}_1 & \text{BodyAccY}_1 & \dots & \text{TotalAccZ}_1 \\
\text{BodyAccX}_2 & \text{BodyAccY}_2 & \dots & \text{TotalAccZ}_2 \\
\vdots & \vdots & \ddots & \vdots \\
\text{BodyAccX}_{128} & \text{BodyAccY}_{128} & \dots & \text{TotalAccZ}_{128} 
\end{bmatrix} \in \mathbb{R}^{128 \times 9}
\]

\subsubsection{2. Volumetria Total dos
Dados}\label{volumetria-total-dos-dados}

O conjunto total foi particionado estaticamente para garantir
reprodutibilidade. A dimensão massiva dos dados brutos processados é
detalhada abaixo:

\begin{center}
\textbf{Tabela 1: Distribuição e Dimensão dos Dados}
\end{center}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2105}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2632}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2632}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2632}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Conjunto
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Quantidade de Amostras (\(N\))
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dimensão por Amostra
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Total de Pontos de Dados
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Treinamento (70\%)} & 7.352 janelas & \(128 \times 9\) &
\(8.469.504\) valores \\
\textbf{Teste (30\%)} & 2.947 janelas & \(128 \times 9\) & \(3.394.944\)
valores \\
\textbf{TOTAL} & \textbf{10.299 janelas} & - & \textbf{\(\approx\) 11.8
Milhões de valores} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor. \end{center}

\subsection{Pré-processamento: Codificação
One-Hot}\label{pruxe9-processamento-codificauxe7uxe3o-one-hot}

Para viabilizar o treinamento supervisionado, os rótulos categóricos
foram convertidos via \textbf{One-Hot Encoding}.

\begin{center}
\textbf{Tabela 1: Mapeamento de Classes e Codificação One-Hot}
\end{center}

\begin{longtable}[]{@{}clcc@{}}
\toprule\noalign{}
ID Original & Atividade & Índice Python & Vetor One-Hot (Target) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \textbf{Caminhando} & 0 & \texttt{{[}1,\ 0,\ 0,\ 0,\ 0,\ 0{]}} \\
2 & \textbf{Subindo Escadas} & 1 &
\texttt{{[}0,\ 1,\ 0,\ 0,\ 0,\ 0{]}} \\
3 & \textbf{Descendo Escadas} & 2 &
\texttt{{[}0,\ 0,\ 1,\ 0,\ 0,\ 0{]}} \\
4 & \textbf{Sentado} & 3 & \texttt{{[}0,\ 0,\ 0,\ 1,\ 0,\ 0{]}} \\
5 & \textbf{Em Pé} & 4 & \texttt{{[}0,\ 0,\ 0,\ 0,\ 1,\ 0{]}} \\
6 & \textbf{Deitado} & 5 & \texttt{{[}0,\ 0,\ 0,\ 0,\ 0,\ 1{]}} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor. \end{center}

\subsection{Classificação Probabilística
(Softmax)}\label{classificauxe7uxe3o-probabiluxedstica-softmax}

A camada de saída utiliza a função \textbf{Softmax} para transformar os
\emph{logits} \(z\) em probabilidades normalizadas. A probabilidade
\(P(y=i)\) da amostra pertencer à classe \(i\) é dada por:

\[\sigma(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}\]

Onde: * \(z_i\): Logit (saída linear) do neurônio correspondente à
classe \(i\). * \(K\): Número total de classes (\(K=6\) neste estudo). *
\(e\): Constante de Euler (base do logaritmo natural). *
\(\sum_{j=1}^{K} e^{z_j}\): Fator de normalização que garante que a soma
das probabilidades seja 1.

A predição final é a classe com maior probabilidade:
\(\hat{y} = \text{argmax}(\sigma(z))\) (Goodfellow et al., 2016).

\section{Modelagem Computacional
Avançada}\label{modelagem-computacional-avanuxe7ada}

A implementação utilizou Keras/TensorFlow. Abaixo, detalha-se a álgebra
linear exata que ocorre dentro das camadas.

\subsection{Arquitetura A: Stacked LSTM
(Micro-dinâmica)}\label{arquitetura-a-stacked-lstm-micro-dinuxe2mica}

A rede processa a sequência temporal passo a passo (\(t=1 \dots 128\)).

\textbf{1. O Fatiamento (\(x_t\)):} Embora a entrada seja uma matriz
\(128 \times 9\), a LSTM consome uma linha por vez. Para a multiplicação
matricial correta, transpõe-se a linha para um vetor coluna:
\[x_t = (X_{t, :})^T \in \mathbb{R}^{9 \times 1}\]

\textbf{2. A Fusão de Contexto (\(v_{in}\)):} No passo \(t\), a rede
concatena a memória anterior (\(h_{t-1}\)) com a entrada atual
(\(x_t\)):
\[v_{in} = \begin{bmatrix} h_{t-1} \\ x_t \end{bmatrix} \in \mathbb{R}^{137 \times 1} \quad (\text{onde } 128 + 9 = 137)\]

\textbf{3. Parâmetros e Portões:} As matrizes de pesos (\(W\)) devem
projetar esse vetor de 137 de volta para 128 (tamanho da célula).
\[W \in \mathbb{R}^{128 \times 137}\] Isso justifica os \textbf{70.656
parâmetros} da primeira camada
(\(4 \text{ gates} \times [128 \times 137 + 128 \text{ bias}]\)).

\begin{center}
\textbf{Tabela 2: Resumo da Arquitetura Stacked LSTM}
\end{center}

\begin{longtable}[]{@{}lllc@{}}
\toprule\noalign{}
Camada & Configuração & Output Shape & Parâmetros \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LSTM 1 & 128 units, return\_seq=True & (None, 128, 128) & 70.656 \\
Dropout 1 & Rate = 0.3 & (None, 128, 128) & 0 \\
LSTM 2 & 64 units, return\_seq=False & (None, 64) & 49.408 \\
Dense & 64 units, ReLU & (None, 64) & 4.160 \\
Output & 6 units, Softmax & (None, 6) & 390 \\
\textbf{Total} & & & \textbf{124.870} \\
\end{longtable}

\subsection{Arquitetura B: Pure 1D-CNN (Convolução
Multivariada)}\label{arquitetura-b-pure-1d-cnn-convoluuxe7uxe3o-multivariada}

A CNN aplica filtros que deslizam no tempo, mas integram espacialmente
todos os sensores.

\textbf{1. Anatomia do Kernel (\(W\)):} O filtro (\(K=3\)) não é um
vetor, mas uma matriz que cobre \textbf{todas} as 9 variáveis de entrada
simultaneamente. \[W_{kernel} \in \mathbb{R}^{3 \times 9}\]

\textbf{2. Operação de Convolução:} A cada passo de deslizamento, o
kernel computa o produto escalar de todas as 9 variáveis na janela
temporal de 3 passos. Como utilizamos \textbf{64 filtros} na primeira
camada, temos 64 matrizes \(W\) distintas aprendendo padrões diferentes.

\begin{center}
\textbf{Tabela 3: Resumo da Arquitetura 1D-CNN}
\end{center}

\begin{longtable}[]{@{}lllc@{}}
\toprule\noalign{}
Camada & Configuração & Output Shape & Parâmetros \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Conv1D 1 & 64 filtros, k=3 & (None, 126, 64) & 1.792 \\
Conv1D 2 & 128 filtros, k=3 & (None, 61, 128) & 24.704 \\
Conv1D 3 & 256 filtros, k=3 & (None, 28, 256) & 98.560 \\
GAP & Global Average Pooling & (None, 256) & 0 \\
Output & 6 units, Softmax & (None, 6) & 1.542 \\
\textbf{Total} & (Incluindo Dense Interm.) & & \textbf{143.686} \\
\end{longtable}

\section{Análise de Resultados}\label{anuxe1lise-de-resultados}

\subsection{Dinâmica de Convergência e
Teste}\label{dinuxe2mica-de-converguxeancia-e-teste}

A CNN convergiu mais rapidamente, demonstrando maior facilidade em
otimizar gradientes em comparação à recorrência temporal (BPTT) da LSTM.
Nos dados de teste (\(N=2.947\)), a \textbf{1D-CNN} superou a LSTM,
atingindo \textbf{93\% de acurácia global} contra 90\%.

\begin{center}
\textbf{Tabela 4: Comparativo de Métricas por Classe (F1-Score)}
\end{center}

\begin{longtable}[]{@{}lccc@{}}
\toprule\noalign{}
Atividade & Stacked LSTM & Pure 1D-CNN & \(\Delta\) Desempenho \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Caminhando} & 0.95 & \textbf{0.97} & +2\% \\
\textbf{Subindo Escadas} & 0.90 & \textbf{0.96} & +6\% \\
\textbf{Descendo Escadas} & 0.92 & \textbf{0.95} & +3\% \\
\textbf{Sentado} & 0.82 & \textbf{0.84} & +2\% \\
\textbf{Em Pé} & 0.84 & \textbf{0.89} & +5\% \\
\textbf{Deitado} & 0.97 & \textbf{1.00} & +3\% \\
\textbf{Média Global} & \textbf{0.90} & \textbf{0.93} & \textbf{+3\%} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor. \end{center}

\subsection{Limitações Físicas (Análise de
Erros)}\label{limitauxe7uxf5es-fuxedsicas-anuxe1lise-de-erros}

A Figura 3 expõe a principal fronteira de erro: a distinção
\textbf{Sentado vs.~Em Pé}.

\begin{center}
\textbf{Figura 3: Matrizes de Confusão Normalizadas}
\end{center}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{figuras_artigo/fig_matrizes_confusao_lado_a_lado.pdf}

\begin{center} \small Legenda: Esquerda: LSTM; Direita: CNN. A diagonal principal indica acertos. Fonte: Elaborada pelo autor. \end{center}

Em repouso estático, a magnitude da aceleração é dominada pela gravidade
(\(g \approx 9.8 m/s^2\)). Sem variação significativa no giroscópio e
sem um sensor de altitude, os vetores de ``Sentado'' e ``Em Pé'' são
geometricamente quase idênticos (tronco vertical). A CNN lidou melhor
com isso, sugerindo que ela identificou micro-padrões de vibração
postural que a LSTM ignorou.

\section{Conclusão}\label{conclusuxe3o}

Este estudo confirmou que a extração automática de características via
Deep Learning é eficaz para HAR. A arquitetura \textbf{1D-CNN} provou-se
superior à \textbf{Stacked LSTM}, não apenas em acurácia (93\%), mas em
eficiência de treinamento e generalização para a classe ``Deitado''
(100\%). Matematicamente, a convolução mostrou-se mais robusta para
capturar a morfologia do sinal em janelas curtas do que a recorrência
pura.

\section{Referências}\label{referuxeancias}

\textbf{ANGUITA, D. et al.} A Public Domain Dataset for Human Activity
Recognition Using Smartphones. \emph{ESANN}, 2013.

\textbf{GERS, F. A.; SCHMIDHUBER, J.; CUMMINGS, F.} Learning to forget:
Continual prediction with LSTM. \emph{Neural computation}, 12(10), 2000.

\textbf{GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A.} \emph{Deep Learning}.
MIT Press, 2016.

\textbf{HE, K. et al.} Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. \emph{ICCV}, 2015.

\textbf{HOCHREITER, S.; SCHMIDHUBER, J.} Long Short-Term Memory.
\emph{Neural Computation}, 9(8), 1997.

\textbf{IOFFE, S.; SZEGEDY, C.} Batch normalization: Accelerating deep
network training by reducing internal covariate shift. \emph{ICML},
2015.

\textbf{KINGMA, D. P.; BA, J.} Adam: A method for stochastic
optimization. \emph{arXiv preprint arXiv:1412.6980}, 2014.

\textbf{KIRANYAZ, S. et al.} 1D Convolutional Neural Networks and
Applications: A Survey. \emph{MSSP}, 151, 2021.

\textbf{LARA, O. D.; LABRADOR, M. A.} A survey on human activity
recognition using wearable sensors. \emph{IEEE communications surveys \&
tutorials}, 2013.

\textbf{LECUN, Y.; BENGIO, Y.; HINTON, G.} Deep learning. \emph{Nature},
521, 2015.

\textbf{SRIVASTAVA, N. et al.} Dropout: a simple way to prevent neural
networks from overfitting. \emph{JMLR}, 15(1), 2014.




\end{document}
