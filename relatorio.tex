% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  a4paper,
]{article}
\usepackage{xcolor}
\usepackage[top=1.5cm,bottom=2cm,left=3cm,right=2cm]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Análise Comparativa de Arquiteturas de Deep Learning (Stacked LSTM vs.~1D-CNN) no Reconhecimento de Atividades Humanas},
  pdfauthor={Seu Nome Completo},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Análise Comparativa de Arquiteturas de Deep Learning (Stacked
LSTM vs.~1D-CNN) no Reconhecimento de Atividades Humanas}
\author{Seu Nome Completo}
\date{2025-07-12}
\begin{document}
\maketitle


\section{Introdução}\label{introduuxe7uxe3o}

O monitoramento automático de atividades humanas (HAR - \emph{Human
Activity Recognition}) consolidou-se como um vetor de inovação na
computação onipresente e saúde digital (Lara \& Labrador, 2013).
Sensores inerciais miniaturizados, integrados massivamente em
\emph{smartphones} e \emph{wearables}, geram fluxos de dados contínuos
que, quando processados por algoritmos inteligentes, permitem a
inferência de comportamentos complexos.

A problemática central deste domínio reside na natureza estocástica,
ruidosa e dependente do tempo das séries geradas pelo movimento humano.
Enquanto métodos clássicos dependem de \emph{feature engineering}
manual, o Aprendizado Profundo (\emph{Deep Learning}) oferece a
capacidade de aprender representações hierárquicas diretamente dos dados
brutos (LeCun et al., 2015).

Este trabalho propõe um estudo comparativo rigoroso entre duas
arquiteturas de redes neurais profundas: as \textbf{Redes Neurais
Convolucionais Unidimensionais (1D-CNN)}, especializadas em extração de
padrões locais (Kiranyaz et al., 2021), e as \textbf{Redes Neurais
Recorrentes (Stacked LSTM)}, especializadas em dependências temporais
(Hochreiter \& Schmidhuber, 1997). O objetivo é avaliar a eficácia
preditiva, a eficiência de parâmetros e as limitações físicas de cada
topologia utilizando o \emph{dataset} UCI HAR.

\section{Fundamentos Teóricos e
Metodológicos}\label{fundamentos-teuxf3ricos-e-metodoluxf3gicos}

\subsection{Descrição e Natureza dos Dados (UCI
HAR)}\label{descriuxe7uxe3o-e-natureza-dos-dados-uci-har}

O estudo utiliza dados de 30 voluntários realizando Atividades de Vida
Diária (ADL) com um \emph{smartphone} na cintura. A amostragem ocorreu a
50Hz (Anguita et al., 2013).

\begin{center}
\textbf{Figura 1: Sistema de Coordenadas do Smartphone para HAR}
\end{center}

\begin{center}
\includegraphics[width=0.25\linewidth,height=\textheight,keepaspectratio]{figuras_artigo/fig_smartphone_axis.png}
\end{center}

\begin{center} \small Fonte: Adaptado de Anguita et al. (2013). \end{center}

A entrada da rede é um tensor de dimensão \((N, 128, 9)\), onde \(N\) é
o número de amostras, 128 são os passos de tempo (2,56s) e 9 são as
variáveis dinâmicas: 1. \textbf{Aceleração Corporal
(\(Acc_{XYZ}^{body}\)):} 3 canais. Componente de movimento do usuário.
2. \textbf{Aceleração Total (\(Acc_{XYZ}^{total}\)):} 3 canais. Inclui a
gravidade, crucial para distinguir posturas estáticas. 3.
\textbf{Velocidade Angular (\(Gyro_{XYZ}\)):} 3 canais. Rotação do
tronco.

\subsection{Pré-processamento: Codificação
One-Hot}\label{pruxe9-processamento-codificauxe7uxe3o-one-hot}

Para viabilizar o treinamento supervisionado, os rótulos categóricos
foram convertidos via \textbf{One-Hot Encoding}.

\begin{center}
\textbf{Tabela 1: Mapeamento de Classes e Codificação One-Hot}
\end{center}

\begin{longtable}[]{@{}clcc@{}}
\toprule\noalign{}
ID Original & Atividade & Índice Python & Vetor One-Hot (Target) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \textbf{Caminhando} & 0 & \texttt{{[}1,\ 0,\ 0,\ 0,\ 0,\ 0{]}} \\
2 & \textbf{Subindo Escadas} & 1 &
\texttt{{[}0,\ 1,\ 0,\ 0,\ 0,\ 0{]}} \\
3 & \textbf{Descendo Escadas} & 2 &
\texttt{{[}0,\ 0,\ 1,\ 0,\ 0,\ 0{]}} \\
4 & \textbf{Sentado} & 3 & \texttt{{[}0,\ 0,\ 0,\ 1,\ 0,\ 0{]}} \\
5 & \textbf{Em Pé} & 4 & \texttt{{[}0,\ 0,\ 0,\ 0,\ 1,\ 0{]}} \\
6 & \textbf{Deitado} & 5 & \texttt{{[}0,\ 0,\ 0,\ 0,\ 0,\ 1{]}} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor. \end{center}

\subsection{Classificação Probabilística
(Softmax)}\label{classificauxe7uxe3o-probabiluxedstica-softmax}

A camada de saída utiliza a função \textbf{Softmax} para transformar os
\emph{logits} \(z\) em probabilidades normalizadas. A probabilidade
\(P(y=i)\) da amostra pertencer à classe \(i\) é dada por:

\[\sigma(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}\]

Onde: * \(z_i\): Logit (saída linear) do neurônio correspondente à
classe \(i\). * \(K\): Número total de classes (\(K=6\) neste estudo). *
\(e\): Constante de Euler (base do logaritmo natural). *
\(\sum_{j=1}^{K} e^{z_j}\): Fator de normalização que garante que a soma
das probabilidades seja 1.

A predição final é a classe com maior probabilidade:
\(\hat{y} = \text{argmax}(\sigma(z))\) (Goodfellow et al., 2016).

\section{Modelagem Computacional e
Arquiteturas}\label{modelagem-computacional-e-arquiteturas}

A implementação foi realizada via Keras/TensorFlow. Abaixo, detalha-se a
configuração exata e o cálculo teórico de complexidade de cada modelo.

\subsection{Arquitetura A: Stacked LSTM
(Recorrente)}\label{arquitetura-a-stacked-lstm-recorrente}

A rede utiliza duas camadas LSTM em série para extração profunda de
tempo.

\textbf{Cálculo Teórico de Parâmetros:} A fórmula para LSTM é
\(P = 4 \times [h \times (h + x + 1)]\). * \textbf{LSTM 1 (128 units):}
\(4 \times [128 \times (128 + 9 + 1)] = 70.656\). * \textbf{LSTM 2 (64
units):} \(4 \times [64 \times (64 + 128 + 1)] = 49.408\). *
\textbf{Total Estimado:} \textasciitilde124k parâmetros.

\begin{center}
\textbf{Tabela 2: Resumo da Arquitetura Stacked LSTM}
\end{center}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1852}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1852}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1852}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Camada
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Configuração
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Inicialização Pesos
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dropout Rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output Shape
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Parâmetros
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LSTM 1 & 128 units, return\_seq=True & He Normal & - & (None, 128, 128)
& 70.656 \\
Dropout 1 & - & - & 0.3 & (None, 128, 128) & 0 \\
LSTM 2 & 64 units, return\_seq=False & He Normal & - & (None, 64) &
49.408 \\
Dropout 2 & - & - & 0.3 & (None, 64) & 0 \\
BatchNormalization & - & - & - & (None, 64) & 256 \\
Dense 1 & 64 units, ReLU & He Normal & 0.2 & (None, 64) & 4.160 \\
Output & 6 units, Softmax & Glorot Uniform & - & (None, 6) & 390 \\
\textbf{Total} & & & & & \textbf{124.870} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor com dados do Keras. \end{center}

\subsection{Arquitetura B: Pure 1D-CNN
(Convolucional)}\label{arquitetura-b-pure-1d-cnn-convolucional}

Utiliza três blocos de convolução progressiva seguidos de \emph{Global
Average Pooling} (GAP).

\textbf{Cálculo Teórico de Parâmetros:} A fórmula para Conv1D é
\(P = (k \times C_{in} \times F) + F\). * \textbf{Conv 1:}
\((3 \times 9 \times 64) + 64 = 1.792\). * \textbf{Conv 2:}
\((3 \times 64 \times 128) + 128 = 24.704\). * \textbf{Conv 3:}
\((3 \times 128 \times 256) + 256 = 98.560\). * \textbf{Total Estimado:}
\textasciitilde143k parâmetros.

\begin{center}
\textbf{Tabela 3: Resumo da Arquitetura 1D-CNN}
\end{center}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1852}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1852}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\centering\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1852}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Camada
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Configuração
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Inicialização Pesos
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Dropout Rate
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output Shape
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Parâmetros
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Conv1D 1 & 64 filtros, k=3 & He Normal & - & (None, 126, 64) & 1.792 \\
Conv1D 2 & 128 filtros, k=3 & He Normal & - & (None, 61, 128) &
24.704 \\
Conv1D 3 & 256 filtros, k=3 & He Normal & - & (None, 28, 256) &
98.560 \\
GAP & Global Average & - & 0.5 & (None, 256) & 0 \\
Dense 1 & 64 units, ReLU & He Normal & 0.25 & (None, 64) & 16.448 \\
Output & 6 units, Softmax & Glorot Uniform & - & (None, 6) & 390 \\
\textbf{Total} & (Incluindo BNs) & & & & \textbf{143.686} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor com dados do Keras. \end{center}

\subsection{Configuração de Hiperparâmetros e
Treinamento}\label{configurauxe7uxe3o-de-hiperparuxe2metros-e-treinamento}

Para assegurar a reprodutibilidade e a robustez dos resultados, ambos os
modelos foram submetidos a um protocolo de treinamento rigoroso,
utilizando técnicas de regularização como Dropout (Srivastava et al.,
2014) e Batch Normalization (Ioffe \& Szegedy, 2015).

\begin{center}
\textbf{Tabela 4: Hiperparâmetros e Estratégia de Otimização}
\end{center}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Parâmetro
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Configuração
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Justificativa Teórica
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Otimizador} & Adam & Momento adaptativo (Kingma \& Ba, 2014). \\
\textbf{Taxa de Aprendizado (LR)} & 0.001 (Inicial) & Padrão para
convergência estável. \\
\textbf{Inicialização de Pesos} & He Normal & Otimizada para ReLU (He et
al., 2015). \\
\textbf{Função de Perda} & Categorical Crossentropy & Métrica para
classificação multiclasse. \\
\textbf{Critério de Parada} & Early Stopping (Patience=12) & Previne
overfitting ao monitorar validação. \\
\textbf{Scheduler de LR} & ReduceLROnPlateau & Ajuste fino em platôs de
erro. \\
\textbf{Batch Size} & 64 amostras & Estabilidade estocástica do
gradiente. \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor. \end{center}

\section{Aplicação e Análise de
Resultados}\label{aplicauxe7uxe3o-e-anuxe1lise-de-resultados}

\subsection{Dinâmica de Treinamento}\label{dinuxe2mica-de-treinamento}

A Figura 2 ilustra a convergência. A \textbf{1D-CNN (C-D)} converge mais
rapidamente que a \textbf{LSTM (A-B)} nas primeiras épocas,
estabilizando com uma acurácia elevada, enquanto a LSTM exige mais
épocas para refinar as dependências temporais.

\begin{center}
\textbf{Figura 2: Painel de Desempenho (Treino vs Validação)}
\end{center}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{figuras_artigo/fig_desempenho_completo.pdf}

\begin{center} \small Legenda: A-B: Stacked LSTM; C-D: Pure 1D-CNN. Linhas sólidas: Treino; Tracejadas: Validação. \\ Fonte: Elaborada pelo autor. \end{center}

\subsection{Avaliação Comparativa (Dados de
Teste)}\label{avaliauxe7uxe3o-comparativa-dados-de-teste}

A robustez foi verificada no conjunto de teste (2.947 amostras).

\subsubsection{Resultados: Stacked LSTM}\label{resultados-stacked-lstm}

O modelo recorrente atingiu uma acurácia global de \textbf{90\%}.

\begin{center}
\textbf{Tabela 5: Métricas Detalhadas - Stacked LSTM}
\end{center}

\begin{longtable}[]{@{}lcccc@{}}
\toprule\noalign{}
Classe & Precision & Recall & F1-Score & Suporte \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Caminhando} & 0.98 & 0.92 & 0.95 & 496 \\
\textbf{Subindo} & 0.87 & 0.92 & 0.90 & 471 \\
\textbf{Descendo} & 0.86 & 1.00 & 0.92 & 420 \\
\textbf{Sentado} & 0.79 & 0.86 & 0.82 & 491 \\
\textbf{Em Pé} & 0.90 & 0.78 & 0.84 & 532 \\
\textbf{Deitado} & \textbf{1.00} & \textbf{0.95} & \textbf{0.97} &
537 \\
\textbf{Média} & \textbf{0.90} & \textbf{0.90} & \textbf{0.90} &
\textbf{2947} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor a partir dos resultados experimentais. \end{center}

\subsubsection{Resultados: Pure 1D-CNN}\label{resultados-pure-1d-cnn}

O modelo convolucional superou o recorrente, atingindo uma acurácia
global de \textbf{93\%}.

\begin{center}
\textbf{Tabela 6: Métricas Detalhadas - Pure 1D-CNN}
\end{center}

\begin{longtable}[]{@{}lcccc@{}}
\toprule\noalign{}
Classe & Precision & Recall & F1-Score & Suporte \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Caminhando} & 1.00 & 0.95 & 0.97 & 496 \\
\textbf{Subindo} & 0.95 & 0.96 & 0.96 & 471 \\
\textbf{Descendo} & 0.91 & 1.00 & 0.95 & 420 \\
\textbf{Sentado} & 0.89 & 0.80 & 0.84 & 491 \\
\textbf{Em Pé} & 0.87 & 0.91 & 0.89 & 532 \\
\textbf{Deitado} & \textbf{1.00} & \textbf{1.00} & \textbf{1.00} &
537 \\
\textbf{Média} & \textbf{0.94} & \textbf{0.93} & \textbf{0.93} &
\textbf{2947} \\
\end{longtable}

\begin{center} \small Fonte: Elaborada pelo autor a partir dos resultados experimentais. \end{center}

\subsection{Análise de Erros e
Confusão}\label{anuxe1lise-de-erros-e-confusuxe3o}

A análise das matrizes de confusão (Figura 3) revela as limitações
físicas do sistema.

\begin{center}
\textbf{Figura 3: Matrizes de Confusão Comparativas (Normalizadas)}
\end{center}

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{figuras_artigo/fig_matrizes_confusao_lado_a_lado.pdf}

\begin{center} \small Legenda: Esquerda: Modelo LSTM; Direita: Modelo 1D-CNN. \\ Fonte: Elaborada pelo autor. \end{center}

\textbf{Discussão dos Resultados:} 1. \textbf{Dinamismo:} Ambas as redes
classificam com precisão quase perfeita movimentos cíclicos (Caminhar,
Subir/Descer Escadas). 2. \textbf{O Dilema Estático:} A maior fonte de
erro, visível em ambas as matrizes, é a confusão entre
\textbf{``Sentado''} e \textbf{``Em Pé''}. * A LSTM teve maior
dificuldade, com Precision de apenas 0.79 para ``Sentado''. * A CNN
melhorou essa distinção (Precision 0.89), mas ainda confunde cerca de
20\% das amostras. * \emph{Causa:} Em repouso, a aceleração total
aproxima-se da gravidade (\(Acc \approx g\)). Sem um barômetro para
medir altitude, a orientação vetorial da gravidade é geometricamente
idêntica nestas duas posturas (tronco ereto).

\section{Conclusão}\label{conclusuxe3o}

Este estudo comparou arquiteturas recorrentes e convolucionais para o
reconhecimento de atividades humanas. A \textbf{1D-CNN} demonstrou
superioridade sobre a \textbf{Stacked LSTM}, atingindo \textbf{93\% de
acurácia} (vs 90\%) com uma convergência de treinamento mais estável e
eficiente.

Apesar da CNN possuir um número ligeiramente maior de parâmetros totais
(143k vs 124k), ela se beneficia da paralelização computacional e da
capacidade de extrair assinaturas morfológicas locais (picos e formas de
onda) que são altamente discriminativas em janelas curtas. A limitação
persistente na distinção postural estática sugere a necessidade futura
de fusão de sensores.

\section{Referências}\label{referuxeancias}

\textbf{ANGUITA, D. et al.} A Public Domain Dataset for Human Activity
Recognition Using Smartphones. \emph{ESANN 2013 proceedings}, Bruges,
Belgium, 2013.

\textbf{GERS, F. A.; SCHMIDHUBER, J.; CUMMINGS, F.} Learning to forget:
Continual prediction with LSTM. \emph{Neural computation}, 12(10),
2451-2471, 2000.

\textbf{GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A.} \emph{Deep Learning}.
MIT Press, 2016.

\textbf{HE, K. et al.} Delving deep into rectifiers: Surpassing
human-level performance on imagenet classification. \emph{ICCV}, 2015.

\textbf{HOCHREITER, S.; SCHMIDHUBER, J.} Long Short-Term Memory.
\emph{Neural Computation}, 9(8), 1735--1780, 1997.

\textbf{IOFFE, S.; SZEGEDY, C.} Batch normalization: Accelerating deep
network training by reducing internal covariate shift. \emph{ICML},
2015.

\textbf{KINGMA, D. P.; BA, J.} Adam: A method for stochastic
optimization. \emph{arXiv preprint arXiv:1412.6980}, 2014.

\textbf{KIRANYAZ, S. et al.} 1D Convolutional Neural Networks and
Applications: A Survey. \emph{Mechanical Systems and Signal Processing},
151, 2021.

\textbf{LARA, O. D.; LABRADOR, M. A.} A survey on human activity
recognition using wearable sensors. \emph{IEEE communications surveys \&
tutorials}, 15(3), 1192-1209, 2013.

\textbf{LECUN, Y.; BENGIO, Y.; HINTON, G.} Deep learning. \emph{Nature},
521(7553), 436-444, 2015.

\textbf{SRIVASTAVA, N. et al.} Dropout: a simple way to prevent neural
networks from overfitting. \emph{The journal of machine learning
research}, 15(1), 1929-1958, 2014.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}




\end{document}
